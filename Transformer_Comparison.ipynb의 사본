{"cells":[{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11395,"status":"ok","timestamp":1720618111542,"user":{"displayName":"1105박시유","userId":"01981089589669408765"},"user_tz":-540},"id":"90G4t3bbBk2u","outputId":"4ba5780f-ed17-43ba-e1f5-9d13d57e0b78"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.4)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (5.9.5)\n"]}],"source":["!pip install tqdm psutil"]},{"cell_type":"code","execution_count":40,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":533263,"status":"ok","timestamp":1720619999544,"user":{"displayName":"1105박시유","userId":"01981089589669408765"},"user_tz":-540},"id":"kLJhKyRgbMsy","outputId":"a6d5a92a-ca0b-481c-fcc7-6ffd28e8df7f"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n","  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n","Epoch 1/20: 100%|██████████| 938/938 [00:24<00:00, 37.95it/s, loss=0.695]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [1/20], Training Loss: 0.3509\n","Epoch [1/20], Validation Loss: 0.2281, Validation Accuracy: 93.00%\n","Epoch [1/20], Time: 27.00s, Memory Usage: 1532.27MB\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2/20: 100%|██████████| 938/938 [00:25<00:00, 37.30it/s, loss=0.0224]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [2/20], Training Loss: 0.1736\n","Epoch [2/20], Validation Loss: 0.1224, Validation Accuracy: 96.31%\n","Epoch [2/20], Time: 27.42s, Memory Usage: 1532.27MB\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3/20: 100%|██████████| 938/938 [00:26<00:00, 35.74it/s, loss=0.176]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [3/20], Training Loss: 0.1396\n","Epoch [3/20], Validation Loss: 0.1425, Validation Accuracy: 95.70%\n","Epoch [3/20], Time: 29.06s, Memory Usage: 1532.27MB\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4/20: 100%|██████████| 938/938 [00:24<00:00, 38.15it/s, loss=0.383]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [4/20], Training Loss: 0.1154\n","Epoch [4/20], Validation Loss: 0.1500, Validation Accuracy: 95.58%\n","Epoch [4/20], Time: 26.83s, Memory Usage: 1532.27MB\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5/20: 100%|██████████| 938/938 [00:22<00:00, 40.85it/s, loss=0.0265]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [5/20], Training Loss: 0.1035\n","Epoch [5/20], Validation Loss: 0.0860, Validation Accuracy: 97.28%\n","Epoch [5/20], Time: 25.11s, Memory Usage: 1532.27MB\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 6/20: 100%|██████████| 938/938 [00:24<00:00, 38.61it/s, loss=0.0964]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [6/20], Training Loss: 0.0917\n","Epoch [6/20], Validation Loss: 0.0984, Validation Accuracy: 96.95%\n","Epoch [6/20], Time: 26.54s, Memory Usage: 1532.27MB\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 7/20: 100%|██████████| 938/938 [00:24<00:00, 38.00it/s, loss=0.146]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [7/20], Training Loss: 0.0881\n","Epoch [7/20], Validation Loss: 0.0814, Validation Accuracy: 97.66%\n","Epoch [7/20], Time: 26.91s, Memory Usage: 1532.27MB\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 8/20: 100%|██████████| 938/938 [00:24<00:00, 38.01it/s, loss=0.152]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [8/20], Training Loss: 0.0864\n","Epoch [8/20], Validation Loss: 0.0987, Validation Accuracy: 97.06%\n","Epoch [8/20], Time: 26.97s, Memory Usage: 1532.27MB\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 9/20: 100%|██████████| 938/938 [00:24<00:00, 38.22it/s, loss=0.0789]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [9/20], Training Loss: 0.0790\n","Epoch [9/20], Validation Loss: 0.0844, Validation Accuracy: 97.42%\n","Epoch [9/20], Time: 26.75s, Memory Usage: 1532.27MB\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 10/20: 100%|██████████| 938/938 [00:23<00:00, 40.52it/s, loss=0.1]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [10/20], Training Loss: 0.0692\n","Epoch [10/20], Validation Loss: 0.0808, Validation Accuracy: 97.70%\n","Epoch [10/20], Time: 25.29s, Memory Usage: 1532.27MB\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 11/20: 100%|██████████| 938/938 [00:23<00:00, 39.53it/s, loss=0.0117]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [11/20], Training Loss: 0.0849\n","Epoch [11/20], Validation Loss: 0.0912, Validation Accuracy: 97.52%\n","Epoch [11/20], Time: 25.96s, Memory Usage: 1532.27MB\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 12/20: 100%|██████████| 938/938 [00:24<00:00, 37.97it/s, loss=0.00871]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [12/20], Training Loss: 0.0632\n","Epoch [12/20], Validation Loss: 0.0897, Validation Accuracy: 97.45%\n","Epoch [12/20], Time: 27.63s, Memory Usage: 1532.27MB\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 13/20: 100%|██████████| 938/938 [00:24<00:00, 37.57it/s, loss=0.137]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [13/20], Training Loss: 0.0717\n","Epoch [13/20], Validation Loss: 0.0826, Validation Accuracy: 97.80%\n","Epoch [13/20], Time: 27.54s, Memory Usage: 1532.27MB\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 14/20: 100%|██████████| 938/938 [00:24<00:00, 38.46it/s, loss=0.0089]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [14/20], Training Loss: 0.0743\n","Epoch [14/20], Validation Loss: 0.0752, Validation Accuracy: 97.84%\n","Epoch [14/20], Time: 26.63s, Memory Usage: 1532.27MB\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 15/20: 100%|██████████| 938/938 [00:23<00:00, 39.88it/s, loss=0.0272]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [15/20], Training Loss: 0.0691\n","Epoch [15/20], Validation Loss: 0.0743, Validation Accuracy: 97.75%\n","Epoch [15/20], Time: 25.73s, Memory Usage: 1532.27MB\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 16/20: 100%|██████████| 938/938 [00:23<00:00, 40.48it/s, loss=0.00766]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [16/20], Training Loss: 0.0467\n","Epoch [16/20], Validation Loss: 0.0821, Validation Accuracy: 97.69%\n","Epoch [16/20], Time: 25.39s, Memory Usage: 1532.27MB\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 17/20: 100%|██████████| 938/938 [00:24<00:00, 38.36it/s, loss=0.276]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [17/20], Training Loss: 0.0555\n","Epoch [17/20], Validation Loss: 0.1572, Validation Accuracy: 95.45%\n","Epoch [17/20], Time: 26.70s, Memory Usage: 1532.27MB\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 18/20: 100%|██████████| 938/938 [00:24<00:00, 38.05it/s, loss=0.164]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [18/20], Training Loss: 0.0578\n","Epoch [18/20], Validation Loss: 0.0806, Validation Accuracy: 97.68%\n","Epoch [18/20], Time: 26.88s, Memory Usage: 1532.27MB\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 19/20: 100%|██████████| 938/938 [00:24<00:00, 38.89it/s, loss=0.0171]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [19/20], Training Loss: 0.0566\n","Epoch [19/20], Validation Loss: 0.0929, Validation Accuracy: 97.30%\n","Epoch [19/20], Time: 26.33s, Memory Usage: 1532.27MB\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 20/20: 100%|██████████| 938/938 [00:23<00:00, 39.47it/s, loss=0.0773]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [20/20], Training Loss: 0.0604\n","Epoch [20/20], Validation Loss: 0.0690, Validation Accuracy: 98.08%\n","Epoch [20/20], Time: 25.90s, Memory Usage: 1532.27MB\n"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision\n","import torchvision.transforms as transforms\n","from torch.utils.data import DataLoader\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm\n","import time\n","import psutil\n","\n","# MNIST 데이터셋 로드 및 전처리\n","transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n","\n","train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n","train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n","\n","test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n","test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n","\n","# Transformer 모델 정의\n","class TransformerModel(nn.Module):\n","    def __init__(self, input_dim, model_dim, num_classes, num_heads, num_layers, dropout=0.1):\n","        super(TransformerModel, self).__init__()\n","        self.embedding = nn.Linear(input_dim, model_dim)\n","        encoder_layer = nn.TransformerEncoderLayer(d_model=model_dim, nhead=num_heads, dropout=dropout)\n","        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n","        self.fc = nn.Linear(model_dim, num_classes)\n","\n","    def forward(self, x):\n","        x = x.view(x.size(0), -1)  # Flatten the input\n","        x = self.embedding(x).unsqueeze(1)  # Add sequence dimension\n","        x = self.transformer_encoder(x)\n","        x = x.mean(dim=1)  # Pooling: average over sequence dimension\n","        x = self.fc(x)\n","        return x\n","\n","# 하이퍼파라미터 설정\n","input_dim = 28 * 28  # MNIST 이미지 크기 (28x28)\n","model_dim = 128\n","num_classes = 10\n","num_heads = 4\n","num_layers = 2\n","num_epochs = 20\n","learning_rate = 0.001\n","\n","# 모델, 손실 함수 및 옵티마이저 초기화\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = TransformerModel(input_dim, model_dim, num_classes, num_heads, num_layers).to(device)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","# 학습 및 검증\n","train_losses = []\n","val_losses = []\n","val_accuracies = []\n","epoch_times = []\n","memory_usages = []\n","overfitting_indicator = []\n","\n","for epoch in range(num_epochs):\n","    model.train()\n","    running_loss = 0.0\n","    start_time = time.time()\n","    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n","\n","    for images, labels in progress_bar:\n","        images, labels = images.to(device), labels.to(device)\n","\n","        optimizer.zero_grad()\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item()\n","        progress_bar.set_postfix(loss=loss.item())\n","\n","    epoch_loss = running_loss / len(train_loader)\n","    train_losses.append(epoch_loss)\n","    print(f\"Epoch [{epoch+1}/{num_epochs}], Training Loss: {epoch_loss:.4f}\")\n","\n","    # 검증 과정\n","    model.eval()\n","    val_loss = 0.0\n","    correct = 0\n","    total = 0\n","\n","    with torch.no_grad():\n","        for images, labels in test_loader:\n","            images, labels = images.to(device), labels.to(device)\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","            val_loss += loss.item()\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","    val_loss /= len(test_loader)\n","    val_accuracy = 100 * correct / total\n","    val_losses.append(val_loss)\n","    val_accuracies.append(val_accuracy)\n","\n","    # 과적합 지표 계산\n","    overfitting_indicator.append(epoch_loss - val_loss)\n","\n","    print(f\"Epoch [{epoch+1}/{num_epochs}], Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%\")\n","\n","    # 에폭 시간 및 메모리 사용량 측정\n","    epoch_time = time.time() - start_time\n","    epoch_times.append(epoch_time)\n","\n","    # 메모리 사용량 측정 (bytes 단위)\n","    memory_usage = psutil.Process().memory_info().rss / 1024 / 1024  # MB 단위로 변환\n","    memory_usages.append(memory_usage)\n","\n","    print(f\"Epoch [{epoch+1}/{num_epochs}], Time: {epoch_time:.2f}s, Memory Usage: {memory_usage:.2f}MB\")\n","li0 = (train_losses, val_accuracies, epoch_times, memory_usages, overfitting_indicator)"]},{"cell_type":"code","execution_count":43,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rLvljQiiByoJ","executionInfo":{"status":"ok","timestamp":1720620342500,"user_tz":-540,"elapsed":287201,"user":{"displayName":"1105박시유","userId":"01981089589669408765"}},"outputId":"fdf8a31a-49ab-4709-c863-03efd7469c2d"},"outputs":[{"output_type":"stream","name":"stderr","text":["Epoch 1/20: 100%|██████████| 938/938 [00:13<00:00, 70.86it/s, loss=0.0712]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [1/20], Training Loss: 0.2288\n","Epoch [1/20], Validation Loss: 0.0885, Validation Accuracy: 97.17%\n","Epoch [1/20], Time: 14.44s, Memory Usage: 1532.60MB\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2/20: 100%|██████████| 938/938 [00:13<00:00, 69.14it/s, loss=0.0156]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [2/20], Training Loss: 0.0849\n","Epoch [2/20], Validation Loss: 0.0904, Validation Accuracy: 97.07%\n","Epoch [2/20], Time: 15.24s, Memory Usage: 1532.60MB\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3/20: 100%|██████████| 938/938 [00:13<00:00, 70.01it/s, loss=0.0113]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [3/20], Training Loss: 0.0566\n","Epoch [3/20], Validation Loss: 0.0784, Validation Accuracy: 97.63%\n","Epoch [3/20], Time: 14.57s, Memory Usage: 1532.60MB\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4/20: 100%|██████████| 938/938 [00:13<00:00, 71.44it/s, loss=0.0136]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [4/20], Training Loss: 0.0420\n","Epoch [4/20], Validation Loss: 0.0778, Validation Accuracy: 97.66%\n","Epoch [4/20], Time: 14.26s, Memory Usage: 1532.60MB\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5/20: 100%|██████████| 938/938 [00:13<00:00, 70.47it/s, loss=0.00694]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [5/20], Training Loss: 0.0339\n","Epoch [5/20], Validation Loss: 0.0845, Validation Accuracy: 97.57%\n","Epoch [5/20], Time: 14.44s, Memory Usage: 1532.60MB\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 6/20: 100%|██████████| 938/938 [00:12<00:00, 74.24it/s, loss=0.00215]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [6/20], Training Loss: 0.0247\n","Epoch [6/20], Validation Loss: 0.0722, Validation Accuracy: 98.18%\n","Epoch [6/20], Time: 13.77s, Memory Usage: 1532.60MB\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 7/20: 100%|██████████| 938/938 [00:12<00:00, 75.41it/s, loss=0.00155]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [7/20], Training Loss: 0.0207\n","Epoch [7/20], Validation Loss: 0.0812, Validation Accuracy: 98.01%\n","Epoch [7/20], Time: 13.58s, Memory Usage: 1532.60MB\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 8/20: 100%|██████████| 938/938 [00:12<00:00, 74.35it/s, loss=0.000882]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [8/20], Training Loss: 0.0201\n","Epoch [8/20], Validation Loss: 0.0841, Validation Accuracy: 98.07%\n","Epoch [8/20], Time: 13.72s, Memory Usage: 1532.60MB\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 9/20: 100%|██████████| 938/938 [00:12<00:00, 72.45it/s, loss=4.03e-5]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [9/20], Training Loss: 0.0188\n","Epoch [9/20], Validation Loss: 0.0840, Validation Accuracy: 97.84%\n","Epoch [9/20], Time: 14.09s, Memory Usage: 1532.60MB\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 10/20: 100%|██████████| 938/938 [00:13<00:00, 68.85it/s, loss=0.167]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [10/20], Training Loss: 0.0165\n","Epoch [10/20], Validation Loss: 0.0787, Validation Accuracy: 98.02%\n","Epoch [10/20], Time: 15.25s, Memory Usage: 1532.60MB\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 11/20: 100%|██████████| 938/938 [00:13<00:00, 70.26it/s, loss=0.000179]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [11/20], Training Loss: 0.0122\n","Epoch [11/20], Validation Loss: 0.0892, Validation Accuracy: 98.11%\n","Epoch [11/20], Time: 14.49s, Memory Usage: 1532.60MB\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 12/20: 100%|██████████| 938/938 [00:13<00:00, 70.09it/s, loss=0.00352]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [12/20], Training Loss: 0.0128\n","Epoch [12/20], Validation Loss: 0.1085, Validation Accuracy: 97.90%\n","Epoch [12/20], Time: 14.60s, Memory Usage: 1532.60MB\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 13/20: 100%|██████████| 938/938 [00:13<00:00, 70.45it/s, loss=0.000557]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [13/20], Training Loss: 0.0158\n","Epoch [13/20], Validation Loss: 0.1122, Validation Accuracy: 97.94%\n","Epoch [13/20], Time: 14.44s, Memory Usage: 1532.60MB\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 14/20: 100%|██████████| 938/938 [00:13<00:00, 71.83it/s, loss=0.000312]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [14/20], Training Loss: 0.0098\n","Epoch [14/20], Validation Loss: 0.0928, Validation Accuracy: 98.32%\n","Epoch [14/20], Time: 14.21s, Memory Usage: 1532.60MB\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 15/20: 100%|██████████| 938/938 [00:13<00:00, 71.79it/s, loss=0.000291]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [15/20], Training Loss: 0.0104\n","Epoch [15/20], Validation Loss: 0.1057, Validation Accuracy: 98.09%\n","Epoch [15/20], Time: 14.22s, Memory Usage: 1532.60MB\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 16/20: 100%|██████████| 938/938 [00:12<00:00, 74.42it/s, loss=3.49e-6]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [16/20], Training Loss: 0.0121\n","Epoch [16/20], Validation Loss: 0.0914, Validation Accuracy: 98.30%\n","Epoch [16/20], Time: 13.77s, Memory Usage: 1532.60MB\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 17/20: 100%|██████████| 938/938 [00:12<00:00, 74.34it/s, loss=0.000106]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [17/20], Training Loss: 0.0102\n","Epoch [17/20], Validation Loss: 0.0985, Validation Accuracy: 98.09%\n","Epoch [17/20], Time: 14.15s, Memory Usage: 1532.60MB\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 18/20: 100%|██████████| 938/938 [00:12<00:00, 72.18it/s, loss=4.26e-6]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [18/20], Training Loss: 0.0086\n","Epoch [18/20], Validation Loss: 0.0860, Validation Accuracy: 98.36%\n","Epoch [18/20], Time: 14.68s, Memory Usage: 1532.60MB\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 19/20: 100%|██████████| 938/938 [00:13<00:00, 70.95it/s, loss=0.000229]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [19/20], Training Loss: 0.0110\n","Epoch [19/20], Validation Loss: 0.0936, Validation Accuracy: 98.17%\n","Epoch [19/20], Time: 14.37s, Memory Usage: 1532.60MB\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 20/20: 100%|██████████| 938/938 [00:13<00:00, 68.94it/s, loss=5.66e-5]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [20/20], Training Loss: 0.0076\n","Epoch [20/20], Validation Loss: 0.1267, Validation Accuracy: 98.13%\n","Epoch [20/20], Time: 14.75s, Memory Usage: 1532.60MB\n"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision\n","import numpy as np\n","import torchvision.transforms as transforms\n","from torch.utils.data import DataLoader\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm\n","import time\n","import psutil\n","\n","train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n","train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n","\n","test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())\n","test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n","\n","# Transformer 모델 정의\n","class TransformerModel(nn.Module):\n","    def __init__(self):\n","        super(TransformerModel, self).__init__()\n","        self.flatten = nn.Flatten()\n","        self.linear_relu_stack = nn.Sequential(\n","            nn.Linear(28*28, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, 10),\n","        )\n","\n","    def forward(self, x):\n","        x = self.flatten(x)\n","        logits = self.linear_relu_stack(x)\n","        return logits\n","\n","# 하이퍼파라미터 설정\n","input_dim = 28 * 28  # MNIST 이미지 크기 (28x28)\n","model_dim = 128\n","num_classes = 10\n","num_heads = 4\n","num_layers = 2\n","num_epochs = 20\n","learning_rate = 0.001\n","\n","# 모델, 손실 함수 및 옵티마이저 초기화\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = TransformerModel().to(device)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","# 학습 및 검증\n","train_losses = []\n","val_losses = []\n","val_accuracies = []\n","epoch_times = []\n","memory_usages = []\n","overfitting_indicator = []\n","\n","for epoch in range(num_epochs):\n","    model.train()\n","    running_loss = 0.0\n","    start_time = time.time()\n","    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n","\n","    for images, labels in progress_bar:\n","        images, labels = images.to(device), labels.to(device)\n","\n","        optimizer.zero_grad()\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item()\n","        progress_bar.set_postfix(loss=loss.item())\n","\n","        epoch_loss = running_loss / len(train_loader)\n","        train_losses.append(epoch_loss)\n","    print(f\"Epoch [{epoch+1}/{num_epochs}], Training Loss: {epoch_loss:.4f}\")\n","\n","    # 검증 과정\n","    model.eval()\n","    val_loss = 0.0\n","    correct = 0\n","    total = 0\n","\n","    with torch.no_grad():\n","        for images, labels in test_loader:\n","            images, labels = images.to(device), labels.to(device)\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","            val_loss += loss.item()\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","    val_loss /= len(test_loader)\n","    val_losses.append(val_loss)\n","    val_accuracy = 100 * correct / total\n","    val_accuracies.append(val_accuracy)\n","\n","    # 과적합 지표 계산\n","    overfitting_indicator.append(epoch_loss - val_loss)\n","\n","    print(f\"Epoch [{epoch+1}/{num_epochs}], Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%\")\n","\n","    # 에폭 시간 및 메모리 사용량 측정\n","    epoch_time = time.time() - start_time\n","    epoch_times.append(epoch_time)\n","\n","    # 메모리 사용량 측정 (bytes 단위)\n","    memory_usage = psutil.Process().memory_info().rss / 1024 / 1024  # MB 단위로 변환\n","    memory_usages.append(memory_usage)\n","\n","    print(f\"Epoch [{epoch+1}/{num_epochs}], Time: {epoch_time:.2f}s, Memory Usage: {memory_usage:.2f}MB\")\n","\n","li1 = (train_losses, val_accuracies, epoch_times, memory_usages, overfitting_indicator)"]},{"cell_type":"code","source":["!pip install performer-pytorch"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YRuzL7MiKkqd","executionInfo":{"status":"ok","timestamp":1720618128393,"user_tz":-540,"elapsed":11290,"user":{"displayName":"1105박시유","userId":"01981089589669408765"}},"outputId":"f25a5c8b-90af-4378-d505-40aa8e0ece6f"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: performer-pytorch in /usr/local/lib/python3.10/dist-packages (1.1.4)\n","Requirement already satisfied: einops>=0.3 in /usr/local/lib/python3.10/dist-packages (from performer-pytorch) (0.8.0)\n","Requirement already satisfied: local-attention>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from performer-pytorch) (1.9.14)\n","Requirement already satisfied: torch>=1.6 in /usr/local/lib/python3.10/dist-packages (from performer-pytorch) (2.3.0+cu121)\n","Requirement already satisfied: axial-positional-embedding>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from performer-pytorch) (0.2.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->performer-pytorch) (3.15.4)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->performer-pytorch) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->performer-pytorch) (1.12.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->performer-pytorch) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->performer-pytorch) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->performer-pytorch) (2023.6.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->performer-pytorch) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->performer-pytorch) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->performer-pytorch) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->performer-pytorch) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->performer-pytorch) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->performer-pytorch) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->performer-pytorch) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->performer-pytorch) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->performer-pytorch) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->performer-pytorch) (2.20.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->performer-pytorch) (12.1.105)\n","Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->performer-pytorch) (2.3.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.6->performer-pytorch) (12.5.82)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6->performer-pytorch) (2.1.5)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6->performer-pytorch) (1.3.0)\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision\n","import torchvision.transforms as transforms\n","from torch.utils.data import DataLoader\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm\n","import time\n","import psutil\n","from performer_pytorch import Performer\n","# MNIST 데이터셋 로드 및 전처리\n","transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n","\n","train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n","train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n","\n","test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n","test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n","\n","# Performer 모델 정의\n","class PerformerModel(nn.Module):\n","    def __init__(self, input_dim, model_dim, num_classes, num_heads, num_layers, dropout=0.1):\n","        super(PerformerModel, self).__init__()\n","        self.embedding = nn.Linear(input_dim, model_dim)\n","        self.performer_encoder = Performer(\n","            dim=model_dim,\n","            depth=num_layers,\n","            heads=num_heads,\n","            dim_head=model_dim // num_heads,\n","            causal=False,\n","            ff_dropout=dropout\n","        )\n","        self.fc = nn.Linear(model_dim, num_classes)\n","\n","    def forward(self, x):\n","        x = x.view(x.size(0), -1)  # Flatten the input\n","        x = self.embedding(x).unsqueeze(1)  # Add sequence dimension\n","        x = self.performer_encoder(x)\n","        x = x.mean(dim=1)  # Pooling: average over sequence dimension\n","        x = self.fc(x)\n","        return x\n","\n","# 하이퍼파라미터 설정\n","input_dim = 28 * 28  # MNIST 이미지 크기 (28x28)\n","model_dim = 128\n","num_classes = 10\n","num_heads = 4\n","num_layers = 2\n","num_epochs = 20\n","learning_rate = 0.001\n","\n","# 모델, 손실 함수 및 옵티마이저 초기화\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = PerformerModel(input_dim, model_dim, num_classes, num_heads, num_layers).to(device)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","# 학습 및 검증\n","train_losses = []\n","val_losses = []\n","val_accuracies = []\n","epoch_times = []\n","memory_usages = []\n","overfitting_indicator = []\n","\n","for epoch in range(num_epochs):\n","    model.train()\n","    running_loss = 0.0\n","    start_time = time.time()\n","    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n","\n","    for images, labels in progress_bar:\n","        images, labels = images.to(device), labels.to(device)\n","\n","        optimizer.zero_grad()\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item()\n","        progress_bar.set_postfix(loss=loss.item())\n","\n","        epoch_loss = running_loss / len(train_loader)\n","        train_losses.append(epoch_loss)\n","    print(f\"Epoch [{epoch+1}/{num_epochs}], Training Loss: {epoch_loss:.4f}\")\n","\n","    # 검증 과정\n","    model.eval()\n","    val_loss = 0.0\n","    correct = 0\n","    total = 0\n","\n","    with torch.no_grad():\n","        for images, labels in test_loader:\n","            images, labels = images.to(device), labels.to(device)\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","            val_loss += loss.item()\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","            val_loss /= len(test_loader)\n","            val_losses.append(val_loss)\n","    val_accuracy = 100 * correct / total\n","    val_accuracies.append(val_accuracy)\n","\n","    # 과적합 지표 계산\n","    overfitting_indicator.append(epoch_loss - val_loss)\n","\n","    print(f\"Epoch [{epoch+1}/{num_epochs}], Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%\")\n","\n","    # 에폭 시간 및 메모리 사용량 측정\n","    epoch_time = time.time() - start_time\n","    epoch_times.append(epoch_time)\n","\n","    # 메모리 사용량 측정 (bytes 단위)\n","    memory_usage = psutil.Process().memory_info().rss / 1024 / 1024  # MB 단위로 변환\n","    memory_usages.append(memory_usage)\n","\n","    print(f\"Epoch [{epoch+1}/{num_epochs}], Time: {epoch_time:.2f}s, Memory Usage: {memory_usage:.2f}MB\")\n","\n","li2 = (train_losses, val_accuracies, epoch_times, memory_usages, overfitting_indicator)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OB-irJB7HySS","executionInfo":{"status":"ok","timestamp":1720621018503,"user_tz":-540,"elapsed":653436,"user":{"displayName":"1105박시유","userId":"01981089589669408765"}},"outputId":"2fc591bd-579f-4036-ca2a-16a160142de9"},"execution_count":44,"outputs":[{"output_type":"stream","name":"stderr","text":["Epoch 1/20: 100%|██████████| 938/938 [00:30<00:00, 30.80it/s, loss=0.151]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [1/20], Training Loss: 0.3065\n","Epoch [1/20], Validation Loss: 0.0010, Validation Accuracy: 93.89%\n","Epoch [1/20], Time: 33.73s, Memory Usage: 1629.96MB\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2/20: 100%|██████████| 938/938 [00:28<00:00, 32.43it/s, loss=0.0862]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [2/20], Training Loss: 0.1468\n","Epoch [2/20], Validation Loss: 0.0005, Validation Accuracy: 95.97%\n","Epoch [2/20], Time: 31.47s, Memory Usage: 1670.28MB\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3/20: 100%|██████████| 938/938 [00:29<00:00, 31.39it/s, loss=0.473]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [3/20], Training Loss: 0.1132\n","Epoch [3/20], Validation Loss: 0.0001, Validation Accuracy: 96.72%\n","Epoch [3/20], Time: 32.61s, Memory Usage: 1670.28MB\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4/20: 100%|██████████| 938/938 [00:30<00:00, 31.01it/s, loss=0.0501]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [4/20], Training Loss: 0.0937\n","Epoch [4/20], Validation Loss: 0.0002, Validation Accuracy: 96.67%\n","Epoch [4/20], Time: 33.56s, Memory Usage: 1670.28MB\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5/20: 100%|██████████| 938/938 [00:30<00:00, 30.59it/s, loss=0.378]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [5/20], Training Loss: 0.0856\n","Epoch [5/20], Validation Loss: 0.0000, Validation Accuracy: 97.02%\n","Epoch [5/20], Time: 33.37s, Memory Usage: 1670.28MB\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 6/20: 100%|██████████| 938/938 [00:30<00:00, 31.19it/s, loss=0.122]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [6/20], Training Loss: 0.0715\n","Epoch [6/20], Validation Loss: 0.0000, Validation Accuracy: 97.16%\n","Epoch [6/20], Time: 32.66s, Memory Usage: 1670.28MB\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 7/20: 100%|██████████| 938/938 [00:29<00:00, 32.14it/s, loss=0.0273]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [7/20], Training Loss: 0.0661\n","Epoch [7/20], Validation Loss: 0.0000, Validation Accuracy: 96.79%\n","Epoch [7/20], Time: 31.78s, Memory Usage: 1670.28MB\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 8/20: 100%|██████████| 938/938 [00:30<00:00, 30.43it/s, loss=0.0158]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [8/20], Training Loss: 0.0627\n","Epoch [8/20], Validation Loss: 0.0000, Validation Accuracy: 97.48%\n","Epoch [8/20], Time: 33.55s, Memory Usage: 1670.28MB\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 9/20: 100%|██████████| 938/938 [00:30<00:00, 30.41it/s, loss=0.0517]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [9/20], Training Loss: 0.0528\n","Epoch [9/20], Validation Loss: 0.0000, Validation Accuracy: 97.76%\n","Epoch [9/20], Time: 33.82s, Memory Usage: 1670.28MB\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 10/20: 100%|██████████| 938/938 [00:29<00:00, 31.79it/s, loss=0.0192]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [10/20], Training Loss: 0.0532\n","Epoch [10/20], Validation Loss: 0.0000, Validation Accuracy: 97.13%\n","Epoch [10/20], Time: 32.12s, Memory Usage: 1670.28MB\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 11/20: 100%|██████████| 938/938 [00:28<00:00, 32.76it/s, loss=0.213]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [11/20], Training Loss: 0.0501\n","Epoch [11/20], Validation Loss: 0.0000, Validation Accuracy: 97.68%\n","Epoch [11/20], Time: 31.29s, Memory Usage: 1670.28MB\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 12/20: 100%|██████████| 938/938 [00:30<00:00, 31.10it/s, loss=0.000236]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [12/20], Training Loss: 0.0422\n","Epoch [12/20], Validation Loss: 0.0000, Validation Accuracy: 97.99%\n","Epoch [12/20], Time: 33.31s, Memory Usage: 1670.28MB\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 13/20: 100%|██████████| 938/938 [00:30<00:00, 30.75it/s, loss=0.0638]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [13/20], Training Loss: 0.0438\n","Epoch [13/20], Validation Loss: 0.0000, Validation Accuracy: 97.43%\n","Epoch [13/20], Time: 33.15s, Memory Usage: 1670.28MB\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 14/20: 100%|██████████| 938/938 [00:30<00:00, 30.73it/s, loss=0.0766]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [14/20], Training Loss: 0.0382\n","Epoch [14/20], Validation Loss: 0.0000, Validation Accuracy: 97.52%\n","Epoch [14/20], Time: 33.23s, Memory Usage: 1670.28MB\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 15/20: 100%|██████████| 938/938 [00:28<00:00, 33.23it/s, loss=0.0278]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [15/20], Training Loss: 0.0411\n","Epoch [15/20], Validation Loss: 0.0000, Validation Accuracy: 98.06%\n","Epoch [15/20], Time: 30.82s, Memory Usage: 1670.54MB\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 16/20: 100%|██████████| 938/938 [00:30<00:00, 31.04it/s, loss=0.109]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [16/20], Training Loss: 0.0359\n","Epoch [16/20], Validation Loss: 0.0000, Validation Accuracy: 97.62%\n","Epoch [16/20], Time: 32.98s, Memory Usage: 1670.54MB\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 17/20: 100%|██████████| 938/938 [00:30<00:00, 30.87it/s, loss=0.101]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [17/20], Training Loss: 0.0391\n","Epoch [17/20], Validation Loss: 0.0000, Validation Accuracy: 97.39%\n","Epoch [17/20], Time: 33.66s, Memory Usage: 1670.79MB\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 18/20: 100%|██████████| 938/938 [00:29<00:00, 31.45it/s, loss=0.00566]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [18/20], Training Loss: 0.0316\n","Epoch [18/20], Validation Loss: 0.0000, Validation Accuracy: 98.15%\n","Epoch [18/20], Time: 32.45s, Memory Usage: 1670.79MB\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 19/20: 100%|██████████| 938/938 [00:29<00:00, 32.00it/s, loss=0.000317]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [19/20], Training Loss: 0.0328\n","Epoch [19/20], Validation Loss: 0.0000, Validation Accuracy: 98.02%\n","Epoch [19/20], Time: 31.88s, Memory Usage: 1670.79MB\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 20/20: 100%|██████████| 938/938 [00:28<00:00, 32.68it/s, loss=3.33e-5]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [20/20], Training Loss: 0.0327\n","Epoch [20/20], Validation Loss: 0.0000, Validation Accuracy: 98.00%\n","Epoch [20/20], Time: 31.42s, Memory Usage: 1670.79MB\n"]}]},{"cell_type":"code","source":["!pip install reformer_pytorch"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HfWh2e6Nx-om","executionInfo":{"status":"ok","timestamp":1720618144996,"user_tz":-540,"elapsed":12589,"user":{"displayName":"1105박시유","userId":"01981089589669408765"}},"outputId":"31046ea4-cc7c-455d-8f88-7bb0857ebc5f"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: reformer_pytorch in /usr/local/lib/python3.10/dist-packages (1.4.4)\n","Requirement already satisfied: axial-positional-embedding>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from reformer_pytorch) (0.2.1)\n","Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from reformer_pytorch) (0.8.0)\n","Requirement already satisfied: local-attention in /usr/local/lib/python3.10/dist-packages (from reformer_pytorch) (1.9.14)\n","Requirement already satisfied: product-key-memory in /usr/local/lib/python3.10/dist-packages (from reformer_pytorch) (0.2.10)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from reformer_pytorch) (2.3.0+cu121)\n","Requirement already satisfied: colt5-attention>=0.10.14 in /usr/local/lib/python3.10/dist-packages (from product-key-memory->reformer_pytorch) (0.11.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->reformer_pytorch) (3.15.4)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->reformer_pytorch) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->reformer_pytorch) (1.12.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->reformer_pytorch) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->reformer_pytorch) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->reformer_pytorch) (2023.6.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->reformer_pytorch) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->reformer_pytorch) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->reformer_pytorch) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->reformer_pytorch) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->reformer_pytorch) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->reformer_pytorch) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->reformer_pytorch) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->reformer_pytorch) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->reformer_pytorch) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch->reformer_pytorch) (2.20.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->reformer_pytorch) (12.1.105)\n","Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->reformer_pytorch) (2.3.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->reformer_pytorch) (12.5.82)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from colt5-attention>=0.10.14->product-key-memory->reformer_pytorch) (24.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->reformer_pytorch) (2.1.5)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->reformer_pytorch) (1.3.0)\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision\n","import torchvision.transforms as transforms\n","from torch.utils.data import DataLoader\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm\n","import time\n","import psutil\n","from reformer_pytorch import Reformer\n","# MNIST 데이터셋 로드 및 전처리\n","transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n","\n","train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n","train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n","\n","test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n","test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n","\n","# Reformer 모델 정의\n","class ReformerModel(nn.Module):\n","    def __init__(self, input_dim, model_dim, num_classes, num_heads, num_layers, dropout=0.1, bucket_size=8):\n","        super(ReformerModel, self).__init__()\n","        self.bucket_size = bucket_size\n","        self.model_dim = model_dim\n","        padded_input_dim = input_dim + (bucket_size * 2 - input_dim % (bucket_size * 2)) % (bucket_size * 2)\n","        self.embedding = nn.Linear(padded_input_dim, model_dim)\n","        self.reformer = Reformer(\n","            dim=model_dim,\n","            depth=num_layers,\n","            heads=num_heads,\n","            bucket_size=bucket_size,\n","            lsh_dropout=dropout,\n","            ff_dropout=dropout\n","        )\n","        self.fc = nn.Linear(model_dim, num_classes)\n","\n","    def forward(self, x):\n","        batch_size = x.size(0)\n","        x = x.view(batch_size, -1)  # Flatten the input\n","        seqlen = x.size(1)\n","        if seqlen % (self.bucket_size * 2) != 0:\n","            pad_len = (self.bucket_size * 2) - (seqlen % (self.bucket_size * 2))\n","            x = torch.cat([x, torch.zeros(batch_size, pad_len).to(x.device)], dim=1)\n","        x = self.embedding(x)\n","        x = x.view(batch_size, -1, self.model_dim)  # Change to (batch_size, sequence_length, model_dim)\n","        x = x.permute(1, 0, 2)  # Change to (sequence_length, batch_size, model_dim) for Reformer\n","        x = self.reformer(x)\n","        x = x.mean(dim=0)  # Pooling: average over sequence dimension\n","        x = self.fc(x)\n","        return x\n","\n","# 하이퍼파라미터 설정\n","input_dim = 28 * 28  # MNIST 이미지 크기 (28x28)\n","model_dim = 128\n","num_classes = 10\n","num_heads = 4\n","num_layers = 2\n","bucket_size = 8  # Set bucket_size to 8 to ensure seqlen % (bucket_size * 2) == 0\n","num_epochs = 20\n","learning_rate = 0.001\n","\n","# 모델, 손실 함수 및 옵티마이저 초기화\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = ReformerModel(input_dim, model_dim, num_classes, num_heads, num_layers, bucket_size=bucket_size).to(device)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","# 학습 및 검증\n","train_losses = []\n","val_losses = []\n","val_accuracies = []\n","epoch_times = []\n","memory_usages = []\n","overfitting_indicator = []\n","\n","for epoch in range(num_epochs):\n","    model.train()\n","    running_loss = 0.0\n","    start_time = time.time()\n","    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n","\n","    for images, labels in progress_bar:\n","        images, labels = images.to(device), labels.to(device)\n","\n","        optimizer.zero_grad()\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item()\n","        progress_bar.set_postfix(loss=loss.item())\n","\n","        epoch_loss = running_loss / len(train_loader)\n","        train_losses.append(epoch_loss)\n","    print(f\"Epoch [{epoch+1}/{num_epochs}], Training Loss: {epoch_loss:.4f}\")\n","\n","    # 검증 과정\n","    model.eval()\n","    val_loss = 0.0\n","    correct = 0\n","    total = 0\n","\n","    with torch.no_grad():\n","        for images, labels in test_loader:\n","            images, labels = images.to(device), labels.to(device)\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","            val_loss += loss.item()\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","    val_loss /= len(test_loader)\n","    val_accuracy = 100 * correct / total\n","    val_losses.append(val_loss)\n","    val_accuracies.append(val_accuracy)\n","\n","    # 과적합 지표 계산\n","    overfitting_indicator.append(epoch_loss - val_loss)\n","\n","    print(f\"Epoch [{epoch+1}/{num_epochs}], Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%\")\n","\n","    # 에폭 시간 및 메모리 사용량 측정\n","    epoch_time = time.time() - start_time\n","    epoch_times.append(epoch_time)\n","\n","    # 메모리 사용량 측정 (bytes 단위)\n","    memory_usage = psutil.Process().memory_info().rss / 1024 / 1024  # MB 단위로 변환\n","    memory_usages.append(memory_usage)\n","\n","    print(f\"Epoch [{epoch+1}/{num_epochs}], Time: {epoch_time:.2f}s, Memory Usage: {memory_usage:.2f}MB\")\n","\n","li3 = (train_losses, val_accuracies, epoch_times, memory_usages, overfitting_indicator)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ndUTKWWryFQN","outputId":"1fb51c90-dacf-49fc-e4fc-acf24cd3be71"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Epoch 1/20: 100%|██████████| 938/938 [01:45<00:00,  8.87it/s, loss=0.366]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [1/20], Training Loss: 0.2843\n","Epoch [1/20], Validation Loss: 0.1459, Validation Accuracy: 95.65%\n","Epoch [1/20], Time: 110.41s, Memory Usage: 1825.61MB\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2/20: 100%|██████████| 938/938 [01:44<00:00,  8.93it/s, loss=0.118]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [2/20], Training Loss: 0.1370\n","Epoch [2/20], Validation Loss: 0.1210, Validation Accuracy: 96.16%\n","Epoch [2/20], Time: 109.38s, Memory Usage: 1825.61MB\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3/20: 100%|██████████| 938/938 [01:48<00:00,  8.61it/s, loss=0.0195]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [3/20], Training Loss: 0.1050\n","Epoch [3/20], Validation Loss: 0.1227, Validation Accuracy: 96.30%\n","Epoch [3/20], Time: 113.56s, Memory Usage: 1825.61MB\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4/20: 100%|██████████| 938/938 [01:43<00:00,  9.05it/s, loss=0.0149]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [4/20], Training Loss: 0.0869\n","Epoch [4/20], Validation Loss: 0.1064, Validation Accuracy: 96.76%\n","Epoch [4/20], Time: 108.30s, Memory Usage: 1825.61MB\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5/20: 100%|██████████| 938/938 [01:42<00:00,  9.17it/s, loss=0.0472]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [5/20], Training Loss: 0.0769\n","Epoch [5/20], Validation Loss: 0.1303, Validation Accuracy: 96.10%\n","Epoch [5/20], Time: 107.74s, Memory Usage: 1825.61MB\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 6/20: 100%|██████████| 938/938 [01:42<00:00,  9.13it/s, loss=0.162]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [6/20], Training Loss: 0.0695\n","Epoch [6/20], Validation Loss: 0.1134, Validation Accuracy: 96.60%\n","Epoch [6/20], Time: 108.03s, Memory Usage: 1825.86MB\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 7/20: 100%|██████████| 938/938 [01:44<00:00,  8.99it/s, loss=0.000445]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [7/20], Training Loss: 0.0658\n","Epoch [7/20], Validation Loss: 0.0773, Validation Accuracy: 97.72%\n","Epoch [7/20], Time: 109.34s, Memory Usage: 1825.86MB\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 8/20: 100%|██████████| 938/938 [01:44<00:00,  8.94it/s, loss=0.0446]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [8/20], Training Loss: 0.0577\n","Epoch [8/20], Validation Loss: 0.0954, Validation Accuracy: 97.49%\n","Epoch [8/20], Time: 109.96s, Memory Usage: 1825.86MB\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 9/20:  52%|█████▏    | 486/938 [00:52<00:44, 10.22it/s, loss=0.0301] "]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision\n","import torchvision.transforms as transforms\n","from torch.utils.data import DataLoader\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm\n","import time\n","import psutil\n","from performer_pytorch import Performer\n","from reformer_pytorch import Reformer\n","\n","# MNIST 데이터셋 로드 및 전처리\n","transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n","\n","train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n","train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n","\n","test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n","test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n","\n","# Performer 모델 정의\n","class PerformerModel(nn.Module):\n","    def __init__(self, input_dim, model_dim, num_classes, num_heads, num_layers, dropout=0.1):\n","        super(PerformerModel, self).__init__()\n","        self.embedding = nn.Linear(input_dim, model_dim)\n","        self.performer_encoder = Performer(\n","            dim=model_dim,\n","            depth=num_layers,\n","            heads=num_heads,\n","            dim_head=model_dim // num_heads,\n","            causal=False,\n","            ff_dropout=dropout\n","        )\n","        self.fc = nn.Linear(model_dim, num_classes)\n","\n","    def forward(self, x):\n","        x = x.view(x.size(0), -1)  # Flatten the input\n","        x = self.embedding(x).unsqueeze(1)  # Add sequence dimension\n","        x = self.performer_encoder(x)\n","        x = x.mean(dim=1)  # Pooling: average over sequence dimension\n","        x = self.fc(x)\n","        return x\n","\n","# Reformer 모델 정의\n","class ReformerModel(nn.Module):\n","    def __init__(self, input_dim, model_dim, num_classes, num_heads, num_layers, dropout=0.1, bucket_size=8):\n","        super(ReformerModel, self).__init__()\n","        self.bucket_size = bucket_size\n","        self.model_dim = model_dim\n","        padded_input_dim = input_dim + (bucket_size * 2 - input_dim % (bucket_size * 2)) % (bucket_size * 2)\n","        self.embedding = nn.Linear(padded_input_dim, model_dim)\n","        self.reformer = Reformer(\n","            dim=model_dim,\n","            depth=num_layers,\n","            heads=num_heads,\n","            bucket_size=bucket_size,\n","            lsh_dropout=dropout,\n","            ff_dropout=dropout\n","        )\n","        self.fc = nn.Linear(model_dim, num_classes)\n","\n","    def forward(self, x):\n","        batch_size = x.size(0)\n","        x = x.view(batch_size, -1)  # Flatten the input\n","        seqlen = x.size(1)\n","        if seqlen % (self.bucket_size * 2) != 0:\n","            pad_len = (self.bucket_size * 2) - (seqlen % (self.bucket_size * 2))\n","            x = torch.cat([x, torch.zeros(batch_size, pad_len).to(x.device)], dim=1)\n","        x = self.embedding(x)\n","        x = x.view(batch_size, -1, self.model_dim)  # Change to (batch_size, sequence_length, model_dim)\n","        x = x.permute(1, 0, 2)  # Change to (sequence_length, batch_size, model_dim) for Reformer\n","        x = self.reformer(x)\n","        x = x.mean(dim=0)  # Pooling: average over sequence dimension\n","        x = self.fc(x)\n","        return x\n","\n","# 통합 모델 정의 (Performer + Reformer)\n","class CombinedModel(nn.Module):\n","    def __init__(self, input_dim, model_dim, num_classes, num_heads, num_layers, dropout=0.1, bucket_size=8):\n","        super(CombinedModel, self).__init__()\n","        self.performer = PerformerModel(input_dim, model_dim, num_classes, num_heads, num_layers, dropout)\n","        self.reformer = ReformerModel(input_dim, model_dim, num_classes, num_heads, num_layers, dropout, bucket_size)\n","        self.fc = nn.Linear(num_classes * 2, num_classes)\n","\n","    def forward(self, x):\n","        performer_out = self.performer(x)\n","        reformer_out = self.reformer(x)\n","        combined_out = torch.cat((performer_out, reformer_out), dim=1)\n","        out = self.fc(combined_out)\n","        return out\n","\n","# 하이퍼파라미터 설정\n","input_dim = 28 * 28  # MNIST 이미지 크기 (28x28)\n","model_dim = 128\n","num_classes = 10\n","num_heads = 4\n","num_layers = 2\n","bucket_size = 8  # Set bucket_size to 8 to ensure seqlen % (bucket_size * 2) == 0\n","num_epochs = 20\n","learning_rate = 0.001\n","\n","# 모델, 손실 함수 및 옵티마이저 초기화\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = CombinedModel(input_dim, model_dim, num_classes, num_heads, num_layers, dropout=0.1, bucket_size=bucket_size).to(device)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","# 학습 및 검증\n","train_losses = []\n","val_losses = []\n","val_accuracies = []\n","epoch_times = []\n","memory_usages = []\n","overfitting_indicator = []\n","\n","for epoch in range(num_epochs):\n","    model.train()\n","    running_loss = 0.0\n","    start_time = time.time()\n","    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n","\n","    for images, labels in progress_bar:\n","        images, labels = images.to(device), labels.to(device)\n","\n","        optimizer.zero_grad()\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item()\n","        progress_bar.set_postfix(loss=loss.item())\n","\n","        epoch_loss = running_loss / len(train_loader)\n","        train_losses.append(epoch_loss)\n","    print(f\"Epoch [{epoch+1}/{num_epochs}], Training Loss: {epoch_loss:.4f}\")\n","\n","    # 검증 과정\n","    model.eval()\n","    val_loss = 0.0\n","    correct = 0\n","    total = 0\n","\n","    with torch.no_grad():\n","        for images, labels in test_loader:\n","            images, labels = images.to(device), labels.to(device)\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","            val_loss += loss.item()\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","    val_loss /= len(test_loader)\n","    val_accuracy = 100 * correct / total\n","    val_losses.append(val_loss)\n","    val_accuracies.append(val_accuracy)\n","\n","    # 과적합 지표 계산\n","    overfitting_indicator.append(epoch_loss - val_loss)\n","\n","    print(f\"Epoch [{epoch+1}/{num_epochs}], Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%\")\n","\n","    # 에폭 시간 및 메모리 사용량 측정\n","    epoch_time = time.time() - start_time\n","    epoch_times.append(epoch_time)\n","\n","    # 메모리 사용량 측정 (bytes 단위)\n","    memory_usage = psutil.Process().memory_info().rss / 1024 / 1024  # MB 단위로 변환\n","    memory_usages.append(memory_usage)\n","\n","    print(f\"Epoch [{epoch+1}/{num_epochs}], Time: {epoch_time:.2f}s, Memory Usage: {memory_usage:.2f}MB\")\n","\n","li4 = (train_losses, val_accuracies, epoch_times, memory_usages, overfitting_indicator)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FHzGvoQ3JyaG","executionInfo":{"status":"ok","timestamp":1720618477406,"user_tz":-540,"elapsed":476,"user":{"displayName":"1105박시유","userId":"01981089589669408765"}},"outputId":"807f0003-9166-4e34-9ce7-ccdec01d382a"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting Preformer.py\n"]}]},{"cell_type":"code","source":["t1, v1, e1, m1, o1 = li\n","t2, v2, e2, m2, o2 = li1\n","t3, v3, e3, m3, o3 = li2\n","t4, v4, e4, m4, o4 = li3\n","t5, v5, e5, m5, o5 = li4\n","# 손실값, 정확도, 시간 및 메모리 사용량 그래프 그리기\n","plt.figure(figsize=(16, 12))\n","\n","plt.subplot(3, 2, 1)\n","plt.plot(t1, label='Training Loss_Transformer')\n","plt.plot(t2, label='Training Loss_Control NN')\n","plt.plot(t3, label='Training Loss_Performer')\n","plt.plot(t4, label='Training Loss_Reformer')\n","plt.plot(t5, label='Training Loss_Preformer')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.xtick(np.arange(0, 20, 2.5, dtype = np.float64))\n","plt.legend()\n","plt.title('Training Loss')\n","\n","plt.subplot(3, 2, 2)\n","plt.plot(v1, label='Validation Accuracy_Transformer')\n","plt.plot(v2, label='Validation Accuracy_Control NN')\n","plt.plot(v3, label='Validation Accuracy_Performer')\n","plt.plot(v4, label='Validation Accuracy_Reformer')\n","plt.plot(v5, label='Validation Accuracy_Preformer')\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy (%)')\n","plt.legend()\n","plt.title('Validation Accuracy')\n","\n","plt.subplot(3, 2, 3)\n","plt.plot(e1, label='Epoch Time_Transformer')\n","plt.plot(e2, label='Epoch Time_Control NN')\n","plt.plot(e3, label='Epoch Time_Performer')\n","plt.plot(e4, label='Epoch Time_Reformer')\n","plt.plot(e5, label='Epoch Time_Preformer')\n","plt.xlabel('Epoch')\n","plt.ylabel('Time (s)')\n","plt.legend()\n","plt.title('Epoch Time')\n","\n","plt.subplot(3, 2, 4)\n","plt.plot(m1, label='Memory Usage_Transformer')\n","plt.plot(m2, label='Memory Usage_Control NN')\n","plt.plot(m3, label='Memory Usage_Performer')\n","plt.plot(m4, label='Memory Usage_Reformer')\n","plt.plot(m5, label='Memory Usage_Preformer')\n","plt.xlabel('Epoch')\n","plt.ylabel('Memory Usage (MB)')\n","plt.legend()\n","plt.title('Memory Usage')\n","\n","plt.subplot(3, 2, 5)\n","plt.plot(o1, label='Overfitting Indicator_Transformer')\n","plt.plot(o2, label='Overfitting Indicator_Control NN')\n","plt.plot(o3, label='Overfitting Indicator_Performer')\n","plt.plot(o4, label='Overfitting Indicator_Reformer')\n","plt.plot(o5, label='Overfitting Indicator_Preformer')\n","plt.xlabel('Epoch')\n","plt.ylabel('Training Loss - Validation Loss')\n","plt.legend()\n","plt.title('Overfitting Indicator')\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"W20qKz6F1WJy","executionInfo":{"status":"error","timestamp":1720619105058,"user_tz":-540,"elapsed":1959,"user":{"displayName":"1105박시유","userId":"01981089589669408765"}},"outputId":"460b3b65-c92e-4491-bf1a-ffcac7a7d816"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n","Files already downloaded and verified\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n","  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n","Epoch 1/20:   0%|          | 0/782 [00:00<?, ?it/s]\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"mat1 and mat2 shapes cannot be multiplied (64x3072 and 1024x128)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-39-4a299a813d19>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mt2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mt3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPerformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/Transformer.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/Transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Flatten the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Add sequence dimension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Pooling: average over sequence dimension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (64x3072 and 1024x128)"]}]},{"cell_type":"code","source":[],"metadata":{"id":"8xlick9Y1d3i"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"1fAO-rdRVUF2ikAo-eDef1O8fghSaL6dU","timestamp":1720621969841}],"authorship_tag":"ABX9TyNNobOGm17UdFuX5pJyKCQN"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}